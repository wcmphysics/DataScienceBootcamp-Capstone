{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify commonly used column names\n",
    "column_name_all = df_source.columns\n",
    "column_name_basic, column_name_smart = column_name_all[:5], column_name_all[5:]\n",
    "column_name_smart_raw = pd.Index([c for c in column_name_smart if \"raw\" in c ])\n",
    "column_name_smart_normalized = pd.Index([c for c in column_name_smart if \"normalized\" in c ])\n",
    "print(column_name_basic)\n",
    "print(column_name_smart_raw)\n",
    "print(column_name_smart_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for reading time series\n",
    "#serials = ['ZLW0EGC6', 'Z305B2QN', 'ZLW0C6NE', 'ZJV0XJQ3', 'ZLW18MKT', 'ZLW0GGTP']\n",
    "serials = ['ZLW0EGC6', 'ZLW0GGTP']\n",
    "start_date = \"2021-10-01\"\n",
    "end_date = \"2021-10-31\"\n",
    "days = pd.Period(end_date).dayofyear - pd.Period(start_date).dayofyear + 1\n",
    "column_to_save = ['date', 'serial_number', 'model', 'capacity_bytes', 'failure', 'smart_1_normalized']\n",
    "#column_to_save = ['date', 'capacity_bytes', 'failure', 'smart_1_normalized']\n",
    "#column_to_save = column_name_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of empty dataframes for concatenation later\n",
    "time_series_dataset = []\n",
    "for serial in serials:\n",
    "    time_series_dataset.append(pd.DataFrame([], columns=column_to_save))\n",
    "\n",
    "memory_used = 0\n",
    "memory_warning_displayed = False\n",
    "print(f\"Read files for building time series from {start_date} to {end_date}; totally {days} days; {len(serials)} serials\")\n",
    "for day in range(days):\n",
    "    date = pd.Period(start_date) + day\n",
    "    print(f\"  reading data for the date {date}; progress: {day+1}/{days}\")\n",
    "    file_path = \"../data/data_Q4_2021/\" + str(date) + \".csv\"\n",
    "    df_tmp = pd.read_csv(file_path, parse_dates=[\"date\"])\n",
    "    for i, serial in enumerate(serials):\n",
    "        df_tmp_serial = df_tmp.query(\"serial_number == @serial\")[column_to_save]\n",
    "        time_series_dataset[i] = pd.concat([time_series_dataset[i], df_tmp_serial], ignore_index=True)\n",
    "        memory_used += time_series_dataset[i].memory_usage(deep=True).sum()\n",
    "    if memory_used/1024**3 > 1 and not memory_warning_displayed:\n",
    "        print(\" ### Warning: memory used for time-series dataframe > 1 GB ###\")\n",
    "        memory_warning_displayed = True\n",
    "\n",
    "print(\"Time series was read successfully\")\n",
    "print(f\"Memory used for dataframe: {(memory_used/1024**3).round(3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_dataset[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save it as CSV**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Save read time series to csv files\")\n",
    "for i, serial in enumerate(serials):\n",
    "    file_path = \"../data/time_series/\" + serial + \"_\" + start_date + \"_to_\" + end_date + \".csv\" \n",
    "    time_series_dataset[i].to_csv(file_path)\n",
    "    print(f\"  save to \\\"{file_path}\\\"; progress {i}/{len(serials)}\")\n",
    "print(\"Time series are saved successfully\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
